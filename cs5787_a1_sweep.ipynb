{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNBuV0bAWdFoLXw5afd8vw2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jioffe502/cs5787_a1/blob/main/cs5787_a1_sweep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-ksyAOkhsr0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiW84CaqlW7p",
        "outputId": "c1dd48c8-7d54-47ea-9604-e722617e0fec"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/cs5787"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLVP9O8yltzF",
        "outputId": "40aa994f-4da9-42ed-940e-852763deab97"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/cs5787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRcWXY06Q4Xu",
        "outputId": "b2638194-d27f-45bc-b46c-5d0c3971b7ee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " accuracy_summary.csv\n",
            " convergence_graphs.png\n",
            " cs5787_a1.ipynb\n",
            " data\n",
            "'Dropout (GELU) (lr=0.001, batch_size=32, dropout=0.3)_weights.pth'\n",
            "'Dropout (GELU) (lr=0.001, batch_size=32, dropout=0.5)_weights.pth'\n",
            "'Dropout (GELU) (lr=0.001, batch_size=32, dropout=0.7)_weights.pth'\n",
            "'Dropout (GELU) (lr=0.001, batch_size=64, dropout=0.3)_weights.pth'\n",
            "'Dropout (GELU) (lr=0.001, batch_size=64, dropout=0.5)_weights.pth'\n",
            "'Dropout (GELU) (lr=0.01, batch_size=128, dropout=0.3)_weights.pth'\n",
            "'Dropout (GELU) (lr=0.01, batch_size=128, dropout=0.5)_weights.pth'\n",
            "'Dropout (GELU) (lr=0.01, batch_size=128, dropout=0.7)_weights.pth'\n",
            "'Dropout (GELU) (lr=0.01, batch_size=32, dropout=0.3)_weights.pth'\n",
            "'Dropout (GELU) (lr=0.01, batch_size=32, dropout=0.5)_weights.pth'\n",
            "'Dropout (GELU) (lr=0.01, batch_size=32, dropout=0.7)_weights.pth'\n",
            "'Dropout (GELU) (lr=0.01, batch_size=64, dropout=0.3)_weights.pth'\n",
            "'Dropout (GELU) (lr=0.01, batch_size=64, dropout=0.5)_weights.pth'\n",
            "'Dropout (GELU) (lr=0.01, batch_size=64, dropout=0.7)_weights.pth'\n",
            "'No Regularization (GELU) (lr=0.0001, batch_size=128)_weights.pth'\n",
            "'No Regularization (GELU) (lr=0.0001, batch_size=32)_weights.pth'\n",
            "'No Regularization (GELU) (lr=0.0001, batch_size=64)_weights.pth'\n",
            "'No Regularization (GELU) (lr=0.001, batch_size=128)_weights.pth'\n",
            "'No Regularization (GELU) (lr=0.001, batch_size=32)_weights.pth'\n",
            "'No Regularization (GELU) (lr=0.001, batch_size=64)_weights.pth'\n",
            "'No Regularization (GELU) (lr=0.01, batch_size=128)_weights.pth'\n",
            "'No Regularization (GELU) (lr=0.01, batch_size=32)_weights.pth'\n",
            "'No Regularization (GELU) (lr=0.01, batch_size=64)_weights.pth'\n",
            " og_weights\n",
            "'Weight Decay (GELU) (lr=0.0001, batch_size=32, weight_decay=0.0001)_weights.pth'\n",
            "'Weight Decay (GELU) (lr=0.0001, batch_size=32, weight_decay=0.001)_weights.pth'\n",
            "'Weight Decay (GELU) (lr=0.0001, batch_size=32, weight_decay=1e-05)_weights.pth'\n",
            "'Weight Decay (GELU) (lr=0.0001, batch_size=64, weight_decay=0.0001)_weights.pth'\n",
            "'Weight Decay (GELU) (lr=0.0001, batch_size=64, weight_decay=0.001)_weights.pth'\n",
            "'Weight Decay (GELU) (lr=0.001, batch_size=128, weight_decay=0.0001)_weights.pth'\n",
            "'Weight Decay (GELU) (lr=0.001, batch_size=128, weight_decay=0.001)_weights.pth'\n",
            "'Weight Decay (GELU) (lr=0.001, batch_size=128, weight_decay=1e-05)_weights.pth'\n",
            "'Weight Decay (GELU) (lr=0.001, batch_size=32, weight_decay=0.0001)_weights.pth'\n",
            "'Weight Decay (GELU) (lr=0.001, batch_size=32, weight_decay=0.001)_weights.pth'\n",
            "'Weight Decay (GELU) (lr=0.001, batch_size=32, weight_decay=1e-05)_weights.pth'\n",
            "'Weight Decay (GELU) (lr=0.001, batch_size=64, weight_decay=0.0001)_weights.pth'\n",
            "'Weight Decay (GELU) (lr=0.001, batch_size=64, weight_decay=0.001)_weights.pth'\n",
            "'Weight Decay (GELU) (lr=0.001, batch_size=64, weight_decay=1e-05)_weights.pth'\n",
            "'Weight Decay (GELU) (lr=0.01, batch_size=128, weight_decay=0.0001)_weights.pth'\n",
            "'Weight Decay (GELU) (lr=0.01, batch_size=128, weight_decay=0.001)_weights.pth'\n",
            "'Weight Decay (GELU) (lr=0.01, batch_size=128, weight_decay=1e-05)_weights.pth'\n",
            "'Weight Decay (GELU) (lr=0.01, batch_size=32, weight_decay=0.0001)_weights.pth'\n",
            "'Weight Decay (GELU) (lr=0.01, batch_size=32, weight_decay=0.001)_weights.pth'\n",
            "'Weight Decay (GELU) (lr=0.01, batch_size=32, weight_decay=1e-05)_weights.pth'\n",
            "'Weight Decay (GELU) (lr=0.01, batch_size=64, weight_decay=0.0001)_weights.pth'\n",
            "'Weight Decay (GELU) (lr=0.01, batch_size=64, weight_decay=0.001)_weights.pth'\n",
            "'Weight Decay (GELU) (lr=0.01, batch_size=64, weight_decay=1e-05)_weights.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import struct\n",
        "import gzip\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3iQSLdCwFBP",
        "outputId": "f1380e83-2325-4c29-a3fc-50187b930b15"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell 2: Custom FashionMNIST Dataset\n",
        "def read_idx(filename):\n",
        "    with gzip.open(filename, 'rb') as f:\n",
        "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
        "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
        "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)\n",
        "\n",
        "class CustomFashionMNIST(Dataset):\n",
        "    def __init__(self, root, train=True, transform=None):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.train = train\n",
        "\n",
        "        if self.train:\n",
        "            self.data = read_idx(f'{self.root}/train-images-idx3-ubyte.gz')\n",
        "            self.targets = read_idx(f'{self.root}/train-labels-idx1-ubyte.gz')\n",
        "        else:\n",
        "            self.data = read_idx(f'{self.root}/test-images-idx3-ubyte.gz')\n",
        "            self.targets = read_idx(f'{self.root}/test-labels-idx1-ubyte.gz')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, target = self.data[index], int(self.targets[index])\n",
        "        img = Image.fromarray(img, mode='L')\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, target\n",
        "\n"
      ],
      "metadata": {
        "id": "wCj4kSqWwKQK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: LeNet5 Model with GELU\n",
        "class LeNet5GELU(nn.Module):\n",
        "    def __init__(self, use_dropout=False, use_batch_norm=False):\n",
        "        super(LeNet5GELU, self).__init__()\n",
        "        self.use_dropout = use_dropout\n",
        "        self.use_batch_norm = use_batch_norm\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "\n",
        "        # Batch normalization layers\n",
        "        if self.use_batch_norm:\n",
        "            self.bn1 = nn.BatchNorm2d(6)\n",
        "            self.bn2 = nn.BatchNorm2d(16)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # First convolutional layer\n",
        "        x = self.conv1(x)\n",
        "        if self.use_batch_norm:\n",
        "            x = self.bn1(x)\n",
        "        x = nn.functional.gelu(x)\n",
        "        x = nn.functional.max_pool2d(x, 2)\n",
        "\n",
        "        # Second convolutional layer\n",
        "        x = self.conv2(x)\n",
        "        if self.use_batch_norm:\n",
        "            x = self.bn2(x)\n",
        "        x = nn.functional.gelu(x)\n",
        "        x = nn.functional.max_pool2d(x, 2)\n",
        "\n",
        "        # Flatten the output\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = nn.functional.gelu(self.fc1(x))\n",
        "        if self.use_dropout:\n",
        "            x = self.dropout(x)\n",
        "        x = nn.functional.gelu(self.fc2(x))\n",
        "        if self.use_dropout:\n",
        "            x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "JY0DpdUvwO7c"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Data Loading and Preprocessing\n",
        "data_path = '/content/drive/MyDrive/cs5787/data'\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = CustomFashionMNIST(root=data_path, train=True, transform=transform)\n",
        "test_dataset = CustomFashionMNIST(root=data_path, train=False, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "a6nABZNhwSNs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Training and Evaluation Functions\n",
        "def train_and_evaluate(model, optimizer, criterion, train_loader, test_loader, num_epochs=50, use_dropout=False):\n",
        "    model.to(device)\n",
        "\n",
        "    train_accuracies = []\n",
        "    test_accuracies = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Evaluate on train set (without dropout)\n",
        "        model.eval()\n",
        "        if use_dropout:\n",
        "            model.dropout.eval()  # Disable dropout for evaluation\n",
        "        train_accuracy = evaluate_model(model, train_loader)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        # Evaluate on test set\n",
        "        test_accuracy = evaluate_model(model, test_loader)\n",
        "        test_accuracies.append(test_accuracy)\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
        "\n",
        "    return train_accuracies, test_accuracies\n",
        "\n",
        "def evaluate_model(model, data_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "NlE1IYrQwWTc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Training Configurations and Execution\n",
        "configs = [\n",
        "    # {\"name\": \"No Regularization (GELU)\", \"dropout\": False, \"weight_decay\": 0, \"batch_norm\": False},\n",
        "    # {\"name\": \"Dropout (GELU)\", \"dropout\": True, \"weight_decay\": 0, \"batch_norm\": False},\n",
        "    # {\"name\": \"Weight Decay (GELU)\", \"dropout\": False, \"weight_decay\": 1e-4, \"batch_norm\": False},\n",
        "    {\"name\": \"Batch Normalization (GELU)\", \"dropout\": False, \"weight_decay\": 0, \"batch_norm\": True}\n",
        "]\n",
        "\n",
        "# Hyperparameters to experiment with\n",
        "learning_rates = [0.01, 0.001, 0.0001]\n",
        "batch_sizes = [32, 64, 128]\n",
        "num_epochs = 20\n",
        "dropout_rates = [0.3, 0.5, 0.7]\n",
        "weight_decay_values = [1e-3, 1e-4, 1e-5]\n",
        "\n",
        "results = {}\n",
        "\n",
        "for config in configs:\n",
        "    print(f\"\\nTraining with {config['name']}:\")\n",
        "\n",
        "    # Experiment with different learning rates and batch sizes\n",
        "    for lr in learning_rates:\n",
        "        for batch_size in batch_sizes:\n",
        "            model = LeNet5GELU(use_dropout=config['dropout'], use_batch_norm=config['batch_norm'])\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            # If using dropout, experiment with different dropout rates\n",
        "            if config['dropout']:\n",
        "                for dropout_rate in dropout_rates:\n",
        "                    model.dropout.p = dropout_rate\n",
        "                    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=config['weight_decay'])\n",
        "\n",
        "                    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "                    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "                    train_accuracies, test_accuracies = train_and_evaluate(model, optimizer, criterion, train_loader, test_loader, num_epochs=num_epochs, use_dropout=config['dropout'])\n",
        "\n",
        "                    key = f\"{config['name']} (lr={lr}, batch_size={batch_size}, dropout={dropout_rate})\"\n",
        "                    results[key] = {\n",
        "                        'train_accuracies': train_accuracies,\n",
        "                        'test_accuracies': test_accuracies,\n",
        "                    }\n",
        "\n",
        "                    print(f\"Final Test Accuracy with {key}: {test_accuracies[-1]:.4f}\")\n",
        "\n",
        "                    # Save model weights\n",
        "                    torch.save(model.state_dict(), f\"{key}_weights.pth\")\n",
        "\n",
        "            # If using weight decay, experiment with different values\n",
        "            elif config['weight_decay'] > 0:\n",
        "                for wd in weight_decay_values:\n",
        "                    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
        "\n",
        "                    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "                    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "                    train_accuracies, test_accuracies = train_and_evaluate(model, optimizer, criterion, train_loader, test_loader, num_epochs=num_epochs, use_dropout=config['dropout'])\n",
        "\n",
        "                    key = f\"{config['name']} (lr={lr}, batch_size={batch_size}, weight_decay={wd})\"\n",
        "                    results[key] = {\n",
        "                        'train_accuracies': train_accuracies,\n",
        "                        'test_accuracies': test_accuracies,\n",
        "                    }\n",
        "\n",
        "                    print(f\"Final Test Accuracy with {key}: {test_accuracies[-1]:.4f}\")\n",
        "\n",
        "                    # Save model weights\n",
        "                    torch.save(model.state_dict(), f\"{key}_weights.pth\")\n",
        "\n",
        "            # For no regularization and batch normalization\n",
        "            else:\n",
        "                optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=config['weight_decay'])\n",
        "\n",
        "                train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "                test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "                train_accuracies, test_accuracies = train_and_evaluate(model, optimizer, criterion, train_loader, test_loader, num_epochs=num_epochs, use_dropout=config['dropout'])\n",
        "\n",
        "                key = f\"{config['name']} (lr={lr}, batch_size={batch_size})\"\n",
        "                results[key] = {\n",
        "                    'train_accuracies': train_accuracies,\n",
        "                    'test_accuracies': test_accuracies,\n",
        "                }\n",
        "\n",
        "                print(f\"Final Test Accuracy with {key}: {test_accuracies[-1]:.4f}\")\n",
        "\n",
        "                # Save model weights\n",
        "                torch.save(model.state_dict(), f\"{key}_weights.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoUtU6x6wYzN",
        "outputId": "3e524888-05a3-4494-81c3-9da4f8c1848d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with Weight Decay (GELU):\n",
            "Epoch [1/20], Train Accuracy: 0.8679, Test Accuracy: 0.8585\n",
            "Epoch [2/20], Train Accuracy: 0.8512, Test Accuracy: 0.8419\n",
            "Epoch [3/20], Train Accuracy: 0.8641, Test Accuracy: 0.8530\n",
            "Epoch [4/20], Train Accuracy: 0.8544, Test Accuracy: 0.8416\n",
            "Epoch [5/20], Train Accuracy: 0.8599, Test Accuracy: 0.8469\n",
            "Epoch [6/20], Train Accuracy: 0.8707, Test Accuracy: 0.8592\n",
            "Epoch [7/20], Train Accuracy: 0.8556, Test Accuracy: 0.8460\n",
            "Epoch [8/20], Train Accuracy: 0.8742, Test Accuracy: 0.8678\n",
            "Epoch [9/20], Train Accuracy: 0.8533, Test Accuracy: 0.8396\n",
            "Epoch [10/20], Train Accuracy: 0.8624, Test Accuracy: 0.8545\n",
            "Epoch [11/20], Train Accuracy: 0.8627, Test Accuracy: 0.8524\n",
            "Epoch [12/20], Train Accuracy: 0.8783, Test Accuracy: 0.8708\n",
            "Epoch [13/20], Train Accuracy: 0.8668, Test Accuracy: 0.8520\n",
            "Epoch [14/20], Train Accuracy: 0.8656, Test Accuracy: 0.8569\n",
            "Epoch [15/20], Train Accuracy: 0.8759, Test Accuracy: 0.8654\n",
            "Epoch [16/20], Train Accuracy: 0.8741, Test Accuracy: 0.8630\n",
            "Epoch [17/20], Train Accuracy: 0.8742, Test Accuracy: 0.8621\n",
            "Epoch [18/20], Train Accuracy: 0.8640, Test Accuracy: 0.8520\n",
            "Epoch [19/20], Train Accuracy: 0.8583, Test Accuracy: 0.8481\n",
            "Epoch [20/20], Train Accuracy: 0.8754, Test Accuracy: 0.8634\n",
            "Final Test Accuracy with Weight Decay (GELU) (lr=0.01, batch_size=32, weight_decay=0.001): 0.8634\n",
            "Epoch [1/20], Train Accuracy: 0.8841, Test Accuracy: 0.8724\n",
            "Epoch [2/20], Train Accuracy: 0.8826, Test Accuracy: 0.8650\n",
            "Epoch [3/20], Train Accuracy: 0.8849, Test Accuracy: 0.8689\n",
            "Epoch [4/20], Train Accuracy: 0.8785, Test Accuracy: 0.8598\n",
            "Epoch [5/20], Train Accuracy: 0.8639, Test Accuracy: 0.8526\n",
            "Epoch [6/20], Train Accuracy: 0.8935, Test Accuracy: 0.8766\n",
            "Epoch [7/20], Train Accuracy: 0.8911, Test Accuracy: 0.8756\n",
            "Epoch [8/20], Train Accuracy: 0.8810, Test Accuracy: 0.8678\n",
            "Epoch [9/20], Train Accuracy: 0.8771, Test Accuracy: 0.8605\n",
            "Epoch [10/20], Train Accuracy: 0.8921, Test Accuracy: 0.8743\n",
            "Epoch [11/20], Train Accuracy: 0.8862, Test Accuracy: 0.8654\n",
            "Epoch [12/20], Train Accuracy: 0.8876, Test Accuracy: 0.8708\n",
            "Epoch [13/20], Train Accuracy: 0.8839, Test Accuracy: 0.8661\n",
            "Epoch [14/20], Train Accuracy: 0.8819, Test Accuracy: 0.8612\n",
            "Epoch [15/20], Train Accuracy: 0.8884, Test Accuracy: 0.8724\n",
            "Epoch [16/20], Train Accuracy: 0.8755, Test Accuracy: 0.8580\n",
            "Epoch [17/20], Train Accuracy: 0.8812, Test Accuracy: 0.8670\n",
            "Epoch [18/20], Train Accuracy: 0.8970, Test Accuracy: 0.8817\n",
            "Epoch [19/20], Train Accuracy: 0.8796, Test Accuracy: 0.8650\n",
            "Epoch [20/20], Train Accuracy: 0.8823, Test Accuracy: 0.8683\n",
            "Final Test Accuracy with Weight Decay (GELU) (lr=0.01, batch_size=32, weight_decay=0.0001): 0.8683\n",
            "Epoch [1/20], Train Accuracy: 0.8638, Test Accuracy: 0.8473\n",
            "Epoch [2/20], Train Accuracy: 0.8858, Test Accuracy: 0.8692\n",
            "Epoch [3/20], Train Accuracy: 0.8667, Test Accuracy: 0.8483\n",
            "Epoch [4/20], Train Accuracy: 0.8880, Test Accuracy: 0.8689\n",
            "Epoch [5/20], Train Accuracy: 0.8886, Test Accuracy: 0.8725\n",
            "Epoch [6/20], Train Accuracy: 0.8925, Test Accuracy: 0.8735\n",
            "Epoch [7/20], Train Accuracy: 0.8951, Test Accuracy: 0.8776\n",
            "Epoch [8/20], Train Accuracy: 0.8882, Test Accuracy: 0.8666\n",
            "Epoch [9/20], Train Accuracy: 0.8986, Test Accuracy: 0.8747\n",
            "Epoch [10/20], Train Accuracy: 0.8886, Test Accuracy: 0.8731\n",
            "Epoch [11/20], Train Accuracy: 0.8904, Test Accuracy: 0.8745\n",
            "Epoch [12/20], Train Accuracy: 0.8976, Test Accuracy: 0.8785\n",
            "Epoch [13/20], Train Accuracy: 0.8901, Test Accuracy: 0.8710\n",
            "Epoch [14/20], Train Accuracy: 0.8742, Test Accuracy: 0.8583\n",
            "Epoch [15/20], Train Accuracy: 0.8912, Test Accuracy: 0.8739\n",
            "Epoch [16/20], Train Accuracy: 0.8923, Test Accuracy: 0.8739\n",
            "Epoch [17/20], Train Accuracy: 0.8951, Test Accuracy: 0.8810\n",
            "Epoch [18/20], Train Accuracy: 0.8816, Test Accuracy: 0.8632\n",
            "Epoch [19/20], Train Accuracy: 0.8937, Test Accuracy: 0.8769\n",
            "Epoch [20/20], Train Accuracy: 0.8949, Test Accuracy: 0.8727\n",
            "Final Test Accuracy with Weight Decay (GELU) (lr=0.01, batch_size=32, weight_decay=1e-05): 0.8727\n",
            "Epoch [1/20], Train Accuracy: 0.8597, Test Accuracy: 0.8546\n",
            "Epoch [2/20], Train Accuracy: 0.8698, Test Accuracy: 0.8604\n",
            "Epoch [3/20], Train Accuracy: 0.8845, Test Accuracy: 0.8756\n",
            "Epoch [4/20], Train Accuracy: 0.8818, Test Accuracy: 0.8725\n",
            "Epoch [5/20], Train Accuracy: 0.8920, Test Accuracy: 0.8808\n",
            "Epoch [6/20], Train Accuracy: 0.8794, Test Accuracy: 0.8665\n",
            "Epoch [7/20], Train Accuracy: 0.8844, Test Accuracy: 0.8697\n",
            "Epoch [8/20], Train Accuracy: 0.8769, Test Accuracy: 0.8660\n",
            "Epoch [9/20], Train Accuracy: 0.8909, Test Accuracy: 0.8798\n",
            "Epoch [10/20], Train Accuracy: 0.8692, Test Accuracy: 0.8593\n",
            "Epoch [11/20], Train Accuracy: 0.8931, Test Accuracy: 0.8828\n",
            "Epoch [12/20], Train Accuracy: 0.8849, Test Accuracy: 0.8704\n",
            "Epoch [13/20], Train Accuracy: 0.8861, Test Accuracy: 0.8726\n",
            "Epoch [14/20], Train Accuracy: 0.8844, Test Accuracy: 0.8736\n",
            "Epoch [15/20], Train Accuracy: 0.8786, Test Accuracy: 0.8640\n",
            "Epoch [16/20], Train Accuracy: 0.8818, Test Accuracy: 0.8660\n",
            "Epoch [17/20], Train Accuracy: 0.8876, Test Accuracy: 0.8737\n",
            "Epoch [18/20], Train Accuracy: 0.8825, Test Accuracy: 0.8710\n",
            "Epoch [19/20], Train Accuracy: 0.8936, Test Accuracy: 0.8800\n",
            "Epoch [20/20], Train Accuracy: 0.8840, Test Accuracy: 0.8664\n",
            "Final Test Accuracy with Weight Decay (GELU) (lr=0.01, batch_size=64, weight_decay=0.001): 0.8664\n",
            "Epoch [1/20], Train Accuracy: 0.8943, Test Accuracy: 0.8768\n",
            "Epoch [2/20], Train Accuracy: 0.8987, Test Accuracy: 0.8828\n",
            "Epoch [3/20], Train Accuracy: 0.8876, Test Accuracy: 0.8729\n",
            "Epoch [4/20], Train Accuracy: 0.8993, Test Accuracy: 0.8780\n",
            "Epoch [5/20], Train Accuracy: 0.9022, Test Accuracy: 0.8840\n",
            "Epoch [6/20], Train Accuracy: 0.8959, Test Accuracy: 0.8786\n",
            "Epoch [7/20], Train Accuracy: 0.9001, Test Accuracy: 0.8824\n",
            "Epoch [8/20], Train Accuracy: 0.8977, Test Accuracy: 0.8780\n",
            "Epoch [9/20], Train Accuracy: 0.9040, Test Accuracy: 0.8824\n",
            "Epoch [10/20], Train Accuracy: 0.9014, Test Accuracy: 0.8784\n",
            "Epoch [11/20], Train Accuracy: 0.9009, Test Accuracy: 0.8797\n",
            "Epoch [12/20], Train Accuracy: 0.8959, Test Accuracy: 0.8742\n",
            "Epoch [13/20], Train Accuracy: 0.8861, Test Accuracy: 0.8693\n",
            "Epoch [14/20], Train Accuracy: 0.9040, Test Accuracy: 0.8881\n",
            "Epoch [15/20], Train Accuracy: 0.9025, Test Accuracy: 0.8847\n",
            "Epoch [16/20], Train Accuracy: 0.8959, Test Accuracy: 0.8750\n",
            "Epoch [17/20], Train Accuracy: 0.8994, Test Accuracy: 0.8824\n",
            "Epoch [18/20], Train Accuracy: 0.9075, Test Accuracy: 0.8908\n",
            "Epoch [19/20], Train Accuracy: 0.8902, Test Accuracy: 0.8700\n",
            "Epoch [20/20], Train Accuracy: 0.8967, Test Accuracy: 0.8762\n",
            "Final Test Accuracy with Weight Decay (GELU) (lr=0.01, batch_size=64, weight_decay=0.0001): 0.8762\n",
            "Epoch [1/20], Train Accuracy: 0.9030, Test Accuracy: 0.8835\n",
            "Epoch [2/20], Train Accuracy: 0.9009, Test Accuracy: 0.8807\n",
            "Epoch [3/20], Train Accuracy: 0.9048, Test Accuracy: 0.8849\n",
            "Epoch [4/20], Train Accuracy: 0.9053, Test Accuracy: 0.8835\n",
            "Epoch [5/20], Train Accuracy: 0.9075, Test Accuracy: 0.8831\n",
            "Epoch [6/20], Train Accuracy: 0.9142, Test Accuracy: 0.8867\n",
            "Epoch [7/20], Train Accuracy: 0.9141, Test Accuracy: 0.8934\n",
            "Epoch [8/20], Train Accuracy: 0.9046, Test Accuracy: 0.8792\n",
            "Epoch [9/20], Train Accuracy: 0.9162, Test Accuracy: 0.8901\n",
            "Epoch [10/20], Train Accuracy: 0.9106, Test Accuracy: 0.8896\n",
            "Epoch [11/20], Train Accuracy: 0.8913, Test Accuracy: 0.8652\n",
            "Epoch [12/20], Train Accuracy: 0.9112, Test Accuracy: 0.8873\n",
            "Epoch [13/20], Train Accuracy: 0.9104, Test Accuracy: 0.8859\n",
            "Epoch [14/20], Train Accuracy: 0.9088, Test Accuracy: 0.8824\n",
            "Epoch [15/20], Train Accuracy: 0.9049, Test Accuracy: 0.8814\n",
            "Epoch [16/20], Train Accuracy: 0.9107, Test Accuracy: 0.8876\n",
            "Epoch [17/20], Train Accuracy: 0.9125, Test Accuracy: 0.8863\n",
            "Epoch [18/20], Train Accuracy: 0.9215, Test Accuracy: 0.8903\n",
            "Epoch [19/20], Train Accuracy: 0.9086, Test Accuracy: 0.8821\n",
            "Epoch [20/20], Train Accuracy: 0.9136, Test Accuracy: 0.8838\n",
            "Final Test Accuracy with Weight Decay (GELU) (lr=0.01, batch_size=64, weight_decay=1e-05): 0.8838\n",
            "Epoch [1/20], Train Accuracy: 0.8430, Test Accuracy: 0.8352\n",
            "Epoch [2/20], Train Accuracy: 0.8766, Test Accuracy: 0.8652\n",
            "Epoch [3/20], Train Accuracy: 0.8756, Test Accuracy: 0.8659\n",
            "Epoch [4/20], Train Accuracy: 0.8880, Test Accuracy: 0.8727\n",
            "Epoch [5/20], Train Accuracy: 0.8850, Test Accuracy: 0.8721\n",
            "Epoch [6/20], Train Accuracy: 0.8973, Test Accuracy: 0.8818\n",
            "Epoch [7/20], Train Accuracy: 0.8919, Test Accuracy: 0.8771\n",
            "Epoch [8/20], Train Accuracy: 0.8943, Test Accuracy: 0.8759\n",
            "Epoch [9/20], Train Accuracy: 0.8881, Test Accuracy: 0.8730\n",
            "Epoch [10/20], Train Accuracy: 0.8954, Test Accuracy: 0.8802\n",
            "Epoch [11/20], Train Accuracy: 0.8976, Test Accuracy: 0.8820\n",
            "Epoch [12/20], Train Accuracy: 0.9035, Test Accuracy: 0.8891\n",
            "Epoch [13/20], Train Accuracy: 0.8992, Test Accuracy: 0.8797\n",
            "Epoch [14/20], Train Accuracy: 0.8896, Test Accuracy: 0.8777\n",
            "Epoch [15/20], Train Accuracy: 0.8957, Test Accuracy: 0.8799\n",
            "Epoch [16/20], Train Accuracy: 0.8922, Test Accuracy: 0.8781\n",
            "Epoch [17/20], Train Accuracy: 0.9031, Test Accuracy: 0.8848\n",
            "Epoch [18/20], Train Accuracy: 0.9003, Test Accuracy: 0.8868\n",
            "Epoch [19/20], Train Accuracy: 0.8927, Test Accuracy: 0.8783\n",
            "Epoch [20/20], Train Accuracy: 0.8978, Test Accuracy: 0.8820\n",
            "Final Test Accuracy with Weight Decay (GELU) (lr=0.01, batch_size=128, weight_decay=0.001): 0.8820\n",
            "Epoch [1/20], Train Accuracy: 0.9045, Test Accuracy: 0.8852\n",
            "Epoch [2/20], Train Accuracy: 0.9075, Test Accuracy: 0.8890\n",
            "Epoch [3/20], Train Accuracy: 0.9099, Test Accuracy: 0.8856\n",
            "Epoch [4/20], Train Accuracy: 0.9145, Test Accuracy: 0.8943\n",
            "Epoch [5/20], Train Accuracy: 0.9079, Test Accuracy: 0.8922\n",
            "Epoch [6/20], Train Accuracy: 0.9162, Test Accuracy: 0.8936\n",
            "Epoch [7/20], Train Accuracy: 0.9178, Test Accuracy: 0.8972\n",
            "Epoch [8/20], Train Accuracy: 0.9110, Test Accuracy: 0.8842\n",
            "Epoch [9/20], Train Accuracy: 0.9151, Test Accuracy: 0.8891\n",
            "Epoch [10/20], Train Accuracy: 0.9153, Test Accuracy: 0.8935\n",
            "Epoch [11/20], Train Accuracy: 0.9072, Test Accuracy: 0.8821\n",
            "Epoch [12/20], Train Accuracy: 0.9193, Test Accuracy: 0.8933\n",
            "Epoch [13/20], Train Accuracy: 0.9126, Test Accuracy: 0.8879\n",
            "Epoch [14/20], Train Accuracy: 0.9147, Test Accuracy: 0.8915\n",
            "Epoch [15/20], Train Accuracy: 0.9214, Test Accuracy: 0.8969\n",
            "Epoch [16/20], Train Accuracy: 0.9146, Test Accuracy: 0.8879\n",
            "Epoch [17/20], Train Accuracy: 0.9141, Test Accuracy: 0.8884\n",
            "Epoch [18/20], Train Accuracy: 0.9152, Test Accuracy: 0.8915\n",
            "Epoch [19/20], Train Accuracy: 0.9144, Test Accuracy: 0.8889\n",
            "Epoch [20/20], Train Accuracy: 0.9218, Test Accuracy: 0.8938\n",
            "Final Test Accuracy with Weight Decay (GELU) (lr=0.01, batch_size=128, weight_decay=0.0001): 0.8938\n",
            "Epoch [1/20], Train Accuracy: 0.9225, Test Accuracy: 0.8887\n",
            "Epoch [2/20], Train Accuracy: 0.9196, Test Accuracy: 0.8912\n",
            "Epoch [3/20], Train Accuracy: 0.9204, Test Accuracy: 0.8926\n",
            "Epoch [4/20], Train Accuracy: 0.9281, Test Accuracy: 0.8928\n",
            "Epoch [5/20], Train Accuracy: 0.9318, Test Accuracy: 0.8998\n",
            "Epoch [6/20], Train Accuracy: 0.9230, Test Accuracy: 0.8899\n",
            "Epoch [7/20], Train Accuracy: 0.9219, Test Accuracy: 0.8910\n",
            "Epoch [8/20], Train Accuracy: 0.9276, Test Accuracy: 0.8938\n",
            "Epoch [9/20], Train Accuracy: 0.9207, Test Accuracy: 0.8914\n",
            "Epoch [10/20], Train Accuracy: 0.9244, Test Accuracy: 0.8902\n",
            "Epoch [11/20], Train Accuracy: 0.9134, Test Accuracy: 0.8853\n",
            "Epoch [12/20], Train Accuracy: 0.9231, Test Accuracy: 0.8881\n",
            "Epoch [13/20], Train Accuracy: 0.9302, Test Accuracy: 0.8947\n",
            "Epoch [14/20], Train Accuracy: 0.9303, Test Accuracy: 0.8925\n",
            "Epoch [15/20], Train Accuracy: 0.9333, Test Accuracy: 0.8958\n",
            "Epoch [16/20], Train Accuracy: 0.9344, Test Accuracy: 0.8989\n",
            "Epoch [17/20], Train Accuracy: 0.9292, Test Accuracy: 0.8928\n",
            "Epoch [18/20], Train Accuracy: 0.9309, Test Accuracy: 0.8923\n",
            "Epoch [19/20], Train Accuracy: 0.9305, Test Accuracy: 0.8943\n",
            "Epoch [20/20], Train Accuracy: 0.9321, Test Accuracy: 0.8954\n",
            "Final Test Accuracy with Weight Decay (GELU) (lr=0.01, batch_size=128, weight_decay=1e-05): 0.8954\n",
            "Epoch [1/20], Train Accuracy: 0.8639, Test Accuracy: 0.8540\n",
            "Epoch [2/20], Train Accuracy: 0.8832, Test Accuracy: 0.8704\n",
            "Epoch [3/20], Train Accuracy: 0.8969, Test Accuracy: 0.8848\n",
            "Epoch [4/20], Train Accuracy: 0.9038, Test Accuracy: 0.8875\n",
            "Epoch [5/20], Train Accuracy: 0.9066, Test Accuracy: 0.8882\n",
            "Epoch [6/20], Train Accuracy: 0.9129, Test Accuracy: 0.8942\n",
            "Epoch [7/20], Train Accuracy: 0.9062, Test Accuracy: 0.8819\n",
            "Epoch [8/20], Train Accuracy: 0.9187, Test Accuracy: 0.8957\n",
            "Epoch [9/20], Train Accuracy: 0.9196, Test Accuracy: 0.8982\n",
            "Epoch [10/20], Train Accuracy: 0.9159, Test Accuracy: 0.8907\n",
            "Epoch [11/20], Train Accuracy: 0.9235, Test Accuracy: 0.8988\n",
            "Epoch [12/20], Train Accuracy: 0.9220, Test Accuracy: 0.8975\n",
            "Epoch [13/20], Train Accuracy: 0.9241, Test Accuracy: 0.8994\n",
            "Epoch [14/20], Train Accuracy: 0.9294, Test Accuracy: 0.9022\n",
            "Epoch [15/20], Train Accuracy: 0.9208, Test Accuracy: 0.8952\n",
            "Epoch [16/20], Train Accuracy: 0.9246, Test Accuracy: 0.8946\n",
            "Epoch [17/20], Train Accuracy: 0.9310, Test Accuracy: 0.9051\n",
            "Epoch [18/20], Train Accuracy: 0.9336, Test Accuracy: 0.9066\n",
            "Epoch [19/20], Train Accuracy: 0.9327, Test Accuracy: 0.9033\n",
            "Epoch [20/20], Train Accuracy: 0.9316, Test Accuracy: 0.8992\n",
            "Final Test Accuracy with Weight Decay (GELU) (lr=0.001, batch_size=32, weight_decay=0.001): 0.8992\n",
            "Epoch [1/20], Train Accuracy: 0.9366, Test Accuracy: 0.9015\n",
            "Epoch [2/20], Train Accuracy: 0.9469, Test Accuracy: 0.9060\n",
            "Epoch [3/20], Train Accuracy: 0.9461, Test Accuracy: 0.9033\n",
            "Epoch [4/20], Train Accuracy: 0.9511, Test Accuracy: 0.9038\n",
            "Epoch [5/20], Train Accuracy: 0.9537, Test Accuracy: 0.9059\n",
            "Epoch [6/20], Train Accuracy: 0.9499, Test Accuracy: 0.8997\n",
            "Epoch [7/20], Train Accuracy: 0.9557, Test Accuracy: 0.9030\n",
            "Epoch [8/20], Train Accuracy: 0.9604, Test Accuracy: 0.9077\n",
            "Epoch [9/20], Train Accuracy: 0.9506, Test Accuracy: 0.8996\n",
            "Epoch [10/20], Train Accuracy: 0.9599, Test Accuracy: 0.9008\n",
            "Epoch [11/20], Train Accuracy: 0.9613, Test Accuracy: 0.9004\n",
            "Epoch [12/20], Train Accuracy: 0.9613, Test Accuracy: 0.9028\n",
            "Epoch [13/20], Train Accuracy: 0.9632, Test Accuracy: 0.9018\n",
            "Epoch [14/20], Train Accuracy: 0.9657, Test Accuracy: 0.9028\n",
            "Epoch [15/20], Train Accuracy: 0.9687, Test Accuracy: 0.8983\n",
            "Epoch [16/20], Train Accuracy: 0.9725, Test Accuracy: 0.8985\n",
            "Epoch [17/20], Train Accuracy: 0.9710, Test Accuracy: 0.9004\n",
            "Epoch [18/20], Train Accuracy: 0.9695, Test Accuracy: 0.8963\n",
            "Epoch [19/20], Train Accuracy: 0.9739, Test Accuracy: 0.8987\n",
            "Epoch [20/20], Train Accuracy: 0.9713, Test Accuracy: 0.8990\n",
            "Final Test Accuracy with Weight Decay (GELU) (lr=0.001, batch_size=32, weight_decay=0.0001): 0.8990\n",
            "Epoch [1/20], Train Accuracy: 0.9725, Test Accuracy: 0.9001\n",
            "Epoch [2/20], Train Accuracy: 0.9725, Test Accuracy: 0.8992\n",
            "Epoch [3/20], Train Accuracy: 0.9762, Test Accuracy: 0.9035\n",
            "Epoch [4/20], Train Accuracy: 0.9758, Test Accuracy: 0.8984\n",
            "Epoch [5/20], Train Accuracy: 0.9770, Test Accuracy: 0.8971\n",
            "Epoch [6/20], Train Accuracy: 0.9785, Test Accuracy: 0.8989\n",
            "Epoch [7/20], Train Accuracy: 0.9755, Test Accuracy: 0.8993\n",
            "Epoch [8/20], Train Accuracy: 0.9748, Test Accuracy: 0.8911\n",
            "Epoch [9/20], Train Accuracy: 0.9772, Test Accuracy: 0.8958\n",
            "Epoch [10/20], Train Accuracy: 0.9769, Test Accuracy: 0.8919\n",
            "Epoch [11/20], Train Accuracy: 0.9741, Test Accuracy: 0.8919\n",
            "Epoch [12/20], Train Accuracy: 0.9831, Test Accuracy: 0.8998\n",
            "Epoch [13/20], Train Accuracy: 0.9802, Test Accuracy: 0.8947\n",
            "Epoch [14/20], Train Accuracy: 0.9818, Test Accuracy: 0.8914\n",
            "Epoch [15/20], Train Accuracy: 0.9822, Test Accuracy: 0.8936\n",
            "Epoch [16/20], Train Accuracy: 0.9836, Test Accuracy: 0.8945\n",
            "Epoch [17/20], Train Accuracy: 0.9779, Test Accuracy: 0.8909\n",
            "Epoch [18/20], Train Accuracy: 0.9748, Test Accuracy: 0.8960\n",
            "Epoch [19/20], Train Accuracy: 0.9857, Test Accuracy: 0.8939\n",
            "Epoch [20/20], Train Accuracy: 0.9801, Test Accuracy: 0.8957\n",
            "Final Test Accuracy with Weight Decay (GELU) (lr=0.001, batch_size=32, weight_decay=1e-05): 0.8957\n",
            "Epoch [1/20], Train Accuracy: 0.8585, Test Accuracy: 0.8447\n",
            "Epoch [2/20], Train Accuracy: 0.8828, Test Accuracy: 0.8693\n",
            "Epoch [3/20], Train Accuracy: 0.8930, Test Accuracy: 0.8789\n",
            "Epoch [4/20], Train Accuracy: 0.9020, Test Accuracy: 0.8856\n",
            "Epoch [5/20], Train Accuracy: 0.8981, Test Accuracy: 0.8804\n",
            "Epoch [6/20], Train Accuracy: 0.9067, Test Accuracy: 0.8900\n",
            "Epoch [7/20], Train Accuracy: 0.9183, Test Accuracy: 0.8951\n",
            "Epoch [8/20], Train Accuracy: 0.9200, Test Accuracy: 0.8977\n",
            "Epoch [9/20], Train Accuracy: 0.9159, Test Accuracy: 0.8948\n",
            "Epoch [10/20], Train Accuracy: 0.9189, Test Accuracy: 0.8970\n",
            "Epoch [11/20], Train Accuracy: 0.9190, Test Accuracy: 0.8964\n",
            "Epoch [12/20], Train Accuracy: 0.9220, Test Accuracy: 0.8959\n",
            "Epoch [13/20], Train Accuracy: 0.9299, Test Accuracy: 0.9044\n",
            "Epoch [14/20], Train Accuracy: 0.9291, Test Accuracy: 0.9018\n",
            "Epoch [15/20], Train Accuracy: 0.9334, Test Accuracy: 0.9041\n",
            "Epoch [16/20], Train Accuracy: 0.9374, Test Accuracy: 0.9067\n",
            "Epoch [17/20], Train Accuracy: 0.9355, Test Accuracy: 0.9059\n",
            "Epoch [18/20], Train Accuracy: 0.9361, Test Accuracy: 0.9050\n",
            "Epoch [19/20], Train Accuracy: 0.9360, Test Accuracy: 0.9013\n",
            "Epoch [20/20], Train Accuracy: 0.9264, Test Accuracy: 0.8918\n",
            "Final Test Accuracy with Weight Decay (GELU) (lr=0.001, batch_size=64, weight_decay=0.001): 0.8918\n",
            "Epoch [1/20], Train Accuracy: 0.9399, Test Accuracy: 0.9040\n",
            "Epoch [2/20], Train Accuracy: 0.9460, Test Accuracy: 0.9053\n",
            "Epoch [3/20], Train Accuracy: 0.9468, Test Accuracy: 0.9020\n",
            "Epoch [4/20], Train Accuracy: 0.9557, Test Accuracy: 0.9053\n",
            "Epoch [5/20], Train Accuracy: 0.9501, Test Accuracy: 0.8998\n",
            "Epoch [6/20], Train Accuracy: 0.9617, Test Accuracy: 0.9089\n",
            "Epoch [7/20], Train Accuracy: 0.9549, Test Accuracy: 0.8997\n",
            "Epoch [8/20], Train Accuracy: 0.9611, Test Accuracy: 0.9049\n",
            "Epoch [9/20], Train Accuracy: 0.9671, Test Accuracy: 0.9079\n",
            "Epoch [10/20], Train Accuracy: 0.9687, Test Accuracy: 0.9048\n",
            "Epoch [11/20], Train Accuracy: 0.9686, Test Accuracy: 0.9047\n",
            "Epoch [12/20], Train Accuracy: 0.9708, Test Accuracy: 0.9030\n",
            "Epoch [13/20], Train Accuracy: 0.9747, Test Accuracy: 0.9032\n",
            "Epoch [14/20], Train Accuracy: 0.9667, Test Accuracy: 0.9034\n",
            "Epoch [15/20], Train Accuracy: 0.9736, Test Accuracy: 0.9025\n",
            "Epoch [16/20], Train Accuracy: 0.9762, Test Accuracy: 0.9032\n",
            "Epoch [17/20], Train Accuracy: 0.9727, Test Accuracy: 0.9011\n",
            "Epoch [18/20], Train Accuracy: 0.9754, Test Accuracy: 0.9025\n",
            "Epoch [19/20], Train Accuracy: 0.9815, Test Accuracy: 0.9021\n",
            "Epoch [20/20], Train Accuracy: 0.9754, Test Accuracy: 0.9023\n",
            "Final Test Accuracy with Weight Decay (GELU) (lr=0.001, batch_size=64, weight_decay=0.0001): 0.9023\n",
            "Epoch [1/20], Train Accuracy: 0.9828, Test Accuracy: 0.9031\n",
            "Epoch [2/20], Train Accuracy: 0.9802, Test Accuracy: 0.9037\n",
            "Epoch [3/20], Train Accuracy: 0.9787, Test Accuracy: 0.9027\n",
            "Epoch [4/20], Train Accuracy: 0.9764, Test Accuracy: 0.8974\n",
            "Epoch [5/20], Train Accuracy: 0.9796, Test Accuracy: 0.8986\n",
            "Epoch [6/20], Train Accuracy: 0.9819, Test Accuracy: 0.8983\n",
            "Epoch [7/20], Train Accuracy: 0.9816, Test Accuracy: 0.8971\n",
            "Epoch [8/20], Train Accuracy: 0.9853, Test Accuracy: 0.8971\n",
            "Epoch [9/20], Train Accuracy: 0.9836, Test Accuracy: 0.8965\n",
            "Epoch [10/20], Train Accuracy: 0.9765, Test Accuracy: 0.8919\n",
            "Epoch [11/20], Train Accuracy: 0.9848, Test Accuracy: 0.8981\n",
            "Epoch [12/20], Train Accuracy: 0.9839, Test Accuracy: 0.8972\n",
            "Epoch [13/20], Train Accuracy: 0.9895, Test Accuracy: 0.8980\n",
            "Epoch [14/20], Train Accuracy: 0.9872, Test Accuracy: 0.8943\n",
            "Epoch [15/20], Train Accuracy: 0.9863, Test Accuracy: 0.8999\n",
            "Epoch [16/20], Train Accuracy: 0.9825, Test Accuracy: 0.8922\n",
            "Epoch [17/20], Train Accuracy: 0.9872, Test Accuracy: 0.8975\n",
            "Epoch [18/20], Train Accuracy: 0.9887, Test Accuracy: 0.8994\n",
            "Epoch [19/20], Train Accuracy: 0.9904, Test Accuracy: 0.8968\n",
            "Epoch [20/20], Train Accuracy: 0.9914, Test Accuracy: 0.8974\n",
            "Final Test Accuracy with Weight Decay (GELU) (lr=0.001, batch_size=64, weight_decay=1e-05): 0.8974\n",
            "Epoch [1/20], Train Accuracy: 0.8401, Test Accuracy: 0.8271\n",
            "Epoch [2/20], Train Accuracy: 0.8775, Test Accuracy: 0.8657\n",
            "Epoch [3/20], Train Accuracy: 0.8865, Test Accuracy: 0.8759\n",
            "Epoch [4/20], Train Accuracy: 0.8954, Test Accuracy: 0.8830\n",
            "Epoch [5/20], Train Accuracy: 0.8970, Test Accuracy: 0.8814\n",
            "Epoch [6/20], Train Accuracy: 0.9027, Test Accuracy: 0.8887\n",
            "Epoch [7/20], Train Accuracy: 0.9081, Test Accuracy: 0.8887\n",
            "Epoch [8/20], Train Accuracy: 0.9129, Test Accuracy: 0.8945\n",
            "Epoch [9/20], Train Accuracy: 0.9134, Test Accuracy: 0.8931\n",
            "Epoch [10/20], Train Accuracy: 0.9208, Test Accuracy: 0.8999\n",
            "Epoch [11/20], Train Accuracy: 0.9239, Test Accuracy: 0.9018\n",
            "Epoch [12/20], Train Accuracy: 0.9214, Test Accuracy: 0.8998\n",
            "Epoch [13/20], Train Accuracy: 0.9240, Test Accuracy: 0.9009\n",
            "Epoch [14/20], Train Accuracy: 0.9268, Test Accuracy: 0.9023\n",
            "Epoch [15/20], Train Accuracy: 0.9248, Test Accuracy: 0.8968\n",
            "Epoch [16/20], Train Accuracy: 0.9253, Test Accuracy: 0.8968\n",
            "Epoch [17/20], Train Accuracy: 0.9289, Test Accuracy: 0.9023\n",
            "Epoch [18/20], Train Accuracy: 0.9342, Test Accuracy: 0.9071\n",
            "Epoch [19/20], Train Accuracy: 0.9333, Test Accuracy: 0.9020\n",
            "Epoch [20/20], Train Accuracy: 0.9380, Test Accuracy: 0.9029\n",
            "Final Test Accuracy with Weight Decay (GELU) (lr=0.001, batch_size=128, weight_decay=0.001): 0.9029\n",
            "Epoch [1/20], Train Accuracy: 0.9401, Test Accuracy: 0.9030\n",
            "Epoch [2/20], Train Accuracy: 0.9380, Test Accuracy: 0.9000\n",
            "Epoch [3/20], Train Accuracy: 0.9479, Test Accuracy: 0.9071\n",
            "Epoch [4/20], Train Accuracy: 0.9541, Test Accuracy: 0.9064\n",
            "Epoch [5/20], Train Accuracy: 0.9542, Test Accuracy: 0.9061\n",
            "Epoch [6/20], Train Accuracy: 0.9584, Test Accuracy: 0.9055\n",
            "Epoch [7/20], Train Accuracy: 0.9519, Test Accuracy: 0.9029\n",
            "Epoch [8/20], Train Accuracy: 0.9631, Test Accuracy: 0.9059\n",
            "Epoch [9/20], Train Accuracy: 0.9645, Test Accuracy: 0.9057\n",
            "Epoch [10/20], Train Accuracy: 0.9616, Test Accuracy: 0.9038\n",
            "Epoch [11/20], Train Accuracy: 0.9624, Test Accuracy: 0.9038\n",
            "Epoch [12/20], Train Accuracy: 0.9641, Test Accuracy: 0.9003\n",
            "Epoch [13/20], Train Accuracy: 0.9674, Test Accuracy: 0.9041\n",
            "Epoch [14/20], Train Accuracy: 0.9715, Test Accuracy: 0.9008\n",
            "Epoch [15/20], Train Accuracy: 0.9705, Test Accuracy: 0.9027\n",
            "Epoch [16/20], Train Accuracy: 0.9705, Test Accuracy: 0.9006\n",
            "Epoch [17/20], Train Accuracy: 0.9754, Test Accuracy: 0.9019\n",
            "Epoch [18/20], Train Accuracy: 0.9767, Test Accuracy: 0.9031\n",
            "Epoch [19/20], Train Accuracy: 0.9819, Test Accuracy: 0.9024\n",
            "Epoch [20/20], Train Accuracy: 0.9754, Test Accuracy: 0.9026\n",
            "Final Test Accuracy with Weight Decay (GELU) (lr=0.001, batch_size=128, weight_decay=0.0001): 0.9026\n",
            "Epoch [1/20], Train Accuracy: 0.9792, Test Accuracy: 0.9040\n",
            "Epoch [2/20], Train Accuracy: 0.9843, Test Accuracy: 0.9031\n",
            "Epoch [3/20], Train Accuracy: 0.9825, Test Accuracy: 0.9049\n",
            "Epoch [4/20], Train Accuracy: 0.9811, Test Accuracy: 0.9006\n",
            "Epoch [5/20], Train Accuracy: 0.9830, Test Accuracy: 0.9018\n",
            "Epoch [6/20], Train Accuracy: 0.9830, Test Accuracy: 0.9008\n",
            "Epoch [7/20], Train Accuracy: 0.9818, Test Accuracy: 0.8980\n",
            "Epoch [8/20], Train Accuracy: 0.9855, Test Accuracy: 0.9017\n",
            "Epoch [9/20], Train Accuracy: 0.9875, Test Accuracy: 0.9018\n",
            "Epoch [10/20], Train Accuracy: 0.9849, Test Accuracy: 0.9027\n",
            "Epoch [11/20], Train Accuracy: 0.9892, Test Accuracy: 0.9065\n",
            "Epoch [12/20], Train Accuracy: 0.9887, Test Accuracy: 0.9031\n",
            "Epoch [13/20], Train Accuracy: 0.9867, Test Accuracy: 0.8984\n",
            "Epoch [14/20], Train Accuracy: 0.9878, Test Accuracy: 0.9003\n",
            "Epoch [15/20], Train Accuracy: 0.9864, Test Accuracy: 0.9010\n",
            "Epoch [16/20], Train Accuracy: 0.9844, Test Accuracy: 0.9008\n",
            "Epoch [17/20], Train Accuracy: 0.9872, Test Accuracy: 0.8997\n",
            "Epoch [18/20], Train Accuracy: 0.9875, Test Accuracy: 0.9029\n",
            "Epoch [19/20], Train Accuracy: 0.9880, Test Accuracy: 0.9008\n",
            "Epoch [20/20], Train Accuracy: 0.9866, Test Accuracy: 0.8971\n",
            "Final Test Accuracy with Weight Decay (GELU) (lr=0.001, batch_size=128, weight_decay=1e-05): 0.8971\n",
            "Epoch [1/20], Train Accuracy: 0.7955, Test Accuracy: 0.7862\n",
            "Epoch [2/20], Train Accuracy: 0.8334, Test Accuracy: 0.8206\n",
            "Epoch [3/20], Train Accuracy: 0.8442, Test Accuracy: 0.8336\n",
            "Epoch [4/20], Train Accuracy: 0.8557, Test Accuracy: 0.8439\n",
            "Epoch [5/20], Train Accuracy: 0.8633, Test Accuracy: 0.8537\n",
            "Epoch [6/20], Train Accuracy: 0.8684, Test Accuracy: 0.8583\n",
            "Epoch [7/20], Train Accuracy: 0.8657, Test Accuracy: 0.8549\n",
            "Epoch [8/20], Train Accuracy: 0.8753, Test Accuracy: 0.8620\n",
            "Epoch [9/20], Train Accuracy: 0.8821, Test Accuracy: 0.8673\n",
            "Epoch [10/20], Train Accuracy: 0.8819, Test Accuracy: 0.8705\n",
            "Epoch [11/20], Train Accuracy: 0.8807, Test Accuracy: 0.8656\n",
            "Epoch [12/20], Train Accuracy: 0.8879, Test Accuracy: 0.8704\n",
            "Epoch [13/20], Train Accuracy: 0.8809, Test Accuracy: 0.8666\n",
            "Epoch [14/20], Train Accuracy: 0.8904, Test Accuracy: 0.8747\n",
            "Epoch [15/20], Train Accuracy: 0.8808, Test Accuracy: 0.8652\n",
            "Epoch [16/20], Train Accuracy: 0.8949, Test Accuracy: 0.8791\n",
            "Epoch [17/20], Train Accuracy: 0.8975, Test Accuracy: 0.8842\n",
            "Epoch [18/20], Train Accuracy: 0.9030, Test Accuracy: 0.8872\n",
            "Epoch [19/20], Train Accuracy: 0.9023, Test Accuracy: 0.8863\n",
            "Epoch [20/20], Train Accuracy: 0.9044, Test Accuracy: 0.8856\n",
            "Final Test Accuracy with Weight Decay (GELU) (lr=0.0001, batch_size=32, weight_decay=0.001): 0.8856\n",
            "Epoch [1/20], Train Accuracy: 0.9038, Test Accuracy: 0.8858\n",
            "Epoch [2/20], Train Accuracy: 0.9080, Test Accuracy: 0.8904\n",
            "Epoch [3/20], Train Accuracy: 0.9086, Test Accuracy: 0.8884\n",
            "Epoch [4/20], Train Accuracy: 0.9074, Test Accuracy: 0.8890\n",
            "Epoch [5/20], Train Accuracy: 0.9136, Test Accuracy: 0.8948\n",
            "Epoch [6/20], Train Accuracy: 0.9140, Test Accuracy: 0.8943\n",
            "Epoch [7/20], Train Accuracy: 0.9110, Test Accuracy: 0.8931\n",
            "Epoch [8/20], Train Accuracy: 0.9151, Test Accuracy: 0.8950\n",
            "Epoch [9/20], Train Accuracy: 0.9187, Test Accuracy: 0.8992\n",
            "Epoch [10/20], Train Accuracy: 0.9185, Test Accuracy: 0.8985\n",
            "Epoch [11/20], Train Accuracy: 0.9219, Test Accuracy: 0.8988\n",
            "Epoch [12/20], Train Accuracy: 0.9135, Test Accuracy: 0.8885\n",
            "Epoch [13/20], Train Accuracy: 0.9237, Test Accuracy: 0.9026\n",
            "Epoch [14/20], Train Accuracy: 0.9195, Test Accuracy: 0.8950\n",
            "Epoch [15/20], Train Accuracy: 0.9215, Test Accuracy: 0.8984\n",
            "Epoch [16/20], Train Accuracy: 0.9245, Test Accuracy: 0.9007\n",
            "Epoch [17/20], Train Accuracy: 0.9283, Test Accuracy: 0.9066\n",
            "Epoch [18/20], Train Accuracy: 0.9240, Test Accuracy: 0.8985\n",
            "Epoch [19/20], Train Accuracy: 0.9260, Test Accuracy: 0.8997\n",
            "Epoch [20/20], Train Accuracy: 0.9318, Test Accuracy: 0.9053\n",
            "Final Test Accuracy with Weight Decay (GELU) (lr=0.0001, batch_size=32, weight_decay=0.0001): 0.9053\n",
            "Epoch [1/20], Train Accuracy: 0.9282, Test Accuracy: 0.9004\n",
            "Epoch [2/20], Train Accuracy: 0.9286, Test Accuracy: 0.9019\n",
            "Epoch [3/20], Train Accuracy: 0.9349, Test Accuracy: 0.9071\n",
            "Epoch [4/20], Train Accuracy: 0.9353, Test Accuracy: 0.9057\n",
            "Epoch [5/20], Train Accuracy: 0.9381, Test Accuracy: 0.9048\n",
            "Epoch [6/20], Train Accuracy: 0.9381, Test Accuracy: 0.9063\n",
            "Epoch [7/20], Train Accuracy: 0.9354, Test Accuracy: 0.9044\n",
            "Epoch [8/20], Train Accuracy: 0.9345, Test Accuracy: 0.9005\n",
            "Epoch [9/20], Train Accuracy: 0.9355, Test Accuracy: 0.9055\n",
            "Epoch [10/20], Train Accuracy: 0.9428, Test Accuracy: 0.9062\n",
            "Epoch [11/20], Train Accuracy: 0.9415, Test Accuracy: 0.9049\n",
            "Epoch [12/20], Train Accuracy: 0.9394, Test Accuracy: 0.9043\n",
            "Epoch [13/20], Train Accuracy: 0.9422, Test Accuracy: 0.9069\n",
            "Epoch [14/20], Train Accuracy: 0.9446, Test Accuracy: 0.9031\n",
            "Epoch [15/20], Train Accuracy: 0.9494, Test Accuracy: 0.9080\n",
            "Epoch [16/20], Train Accuracy: 0.9479, Test Accuracy: 0.9068\n",
            "Epoch [17/20], Train Accuracy: 0.9471, Test Accuracy: 0.9058\n",
            "Epoch [18/20], Train Accuracy: 0.9487, Test Accuracy: 0.9055\n",
            "Epoch [19/20], Train Accuracy: 0.9484, Test Accuracy: 0.9057\n",
            "Epoch [20/20], Train Accuracy: 0.9524, Test Accuracy: 0.9097\n",
            "Final Test Accuracy with Weight Decay (GELU) (lr=0.0001, batch_size=32, weight_decay=1e-05): 0.9097\n",
            "Epoch [1/20], Train Accuracy: 0.7682, Test Accuracy: 0.7598\n",
            "Epoch [2/20], Train Accuracy: 0.8043, Test Accuracy: 0.7931\n",
            "Epoch [3/20], Train Accuracy: 0.8287, Test Accuracy: 0.8191\n",
            "Epoch [4/20], Train Accuracy: 0.8367, Test Accuracy: 0.8248\n",
            "Epoch [5/20], Train Accuracy: 0.8449, Test Accuracy: 0.8341\n",
            "Epoch [6/20], Train Accuracy: 0.8572, Test Accuracy: 0.8463\n",
            "Epoch [7/20], Train Accuracy: 0.8604, Test Accuracy: 0.8503\n",
            "Epoch [8/20], Train Accuracy: 0.8529, Test Accuracy: 0.8445\n",
            "Epoch [9/20], Train Accuracy: 0.8666, Test Accuracy: 0.8573\n",
            "Epoch [10/20], Train Accuracy: 0.8698, Test Accuracy: 0.8625\n",
            "Epoch [11/20], Train Accuracy: 0.8718, Test Accuracy: 0.8572\n",
            "Epoch [12/20], Train Accuracy: 0.8761, Test Accuracy: 0.8673\n",
            "Epoch [13/20], Train Accuracy: 0.8788, Test Accuracy: 0.8675\n",
            "Epoch [14/20], Train Accuracy: 0.8750, Test Accuracy: 0.8627\n",
            "Epoch [15/20], Train Accuracy: 0.8758, Test Accuracy: 0.8679\n",
            "Epoch [16/20], Train Accuracy: 0.8800, Test Accuracy: 0.8707\n",
            "Epoch [17/20], Train Accuracy: 0.8863, Test Accuracy: 0.8732\n",
            "Epoch [18/20], Train Accuracy: 0.8824, Test Accuracy: 0.8696\n",
            "Epoch [19/20], Train Accuracy: 0.8901, Test Accuracy: 0.8769\n",
            "Epoch [20/20], Train Accuracy: 0.8908, Test Accuracy: 0.8801\n",
            "Final Test Accuracy with Weight Decay (GELU) (lr=0.0001, batch_size=64, weight_decay=0.001): 0.8801\n",
            "Epoch [1/20], Train Accuracy: 0.8877, Test Accuracy: 0.8727\n",
            "Epoch [2/20], Train Accuracy: 0.8882, Test Accuracy: 0.8748\n",
            "Epoch [3/20], Train Accuracy: 0.8843, Test Accuracy: 0.8696\n",
            "Epoch [4/20], Train Accuracy: 0.8984, Test Accuracy: 0.8845\n",
            "Epoch [5/20], Train Accuracy: 0.9001, Test Accuracy: 0.8878\n",
            "Epoch [6/20], Train Accuracy: 0.9019, Test Accuracy: 0.8856\n",
            "Epoch [7/20], Train Accuracy: 0.9005, Test Accuracy: 0.8855\n",
            "Epoch [8/20], Train Accuracy: 0.9019, Test Accuracy: 0.8885\n",
            "Epoch [9/20], Train Accuracy: 0.9004, Test Accuracy: 0.8849\n",
            "Epoch [10/20], Train Accuracy: 0.9082, Test Accuracy: 0.8924\n",
            "Epoch [11/20], Train Accuracy: 0.9088, Test Accuracy: 0.8920\n",
            "Epoch [12/20], Train Accuracy: 0.9039, Test Accuracy: 0.8868\n",
            "Epoch [13/20], Train Accuracy: 0.9086, Test Accuracy: 0.8949\n",
            "Epoch [14/20], Train Accuracy: 0.9094, Test Accuracy: 0.8922\n",
            "Epoch [15/20], Train Accuracy: 0.9128, Test Accuracy: 0.8959\n",
            "Epoch [16/20], Train Accuracy: 0.9099, Test Accuracy: 0.8900\n",
            "Epoch [17/20], Train Accuracy: 0.9113, Test Accuracy: 0.8946\n",
            "Epoch [18/20], Train Accuracy: 0.9114, Test Accuracy: 0.8942\n",
            "Epoch [19/20], Train Accuracy: 0.9142, Test Accuracy: 0.8953\n",
            "Epoch [20/20], Train Accuracy: 0.9138, Test Accuracy: 0.8939\n",
            "Final Test Accuracy with Weight Decay (GELU) (lr=0.0001, batch_size=64, weight_decay=0.0001): 0.8939\n",
            "Epoch [1/20], Train Accuracy: 0.9098, Test Accuracy: 0.8882\n",
            "Epoch [2/20], Train Accuracy: 0.9187, Test Accuracy: 0.8970\n",
            "Epoch [3/20], Train Accuracy: 0.9212, Test Accuracy: 0.8983\n",
            "Epoch [4/20], Train Accuracy: 0.9204, Test Accuracy: 0.8965\n",
            "Epoch [5/20], Train Accuracy: 0.9192, Test Accuracy: 0.8953\n",
            "Epoch [6/20], Train Accuracy: 0.9244, Test Accuracy: 0.8999\n",
            "Epoch [7/20], Train Accuracy: 0.9185, Test Accuracy: 0.8955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Plotting Convergence Graphs\n",
        "plt.figure(figsize=(20, 15))\n",
        "best_results = {}\n",
        "\n",
        "for technique in ['No Regularization (GELU)', 'Dropout (GELU)', 'Weight Decay (GELU)', 'Batch Normalization (GELU)']:\n",
        "    best_accuracy = 0\n",
        "    best_key = ''\n",
        "    for key, data in results.items():\n",
        "        if key.startswith(technique) and data['test_accuracies'][-1] > best_accuracy:\n",
        "            best_accuracy = data['test_accuracies'][-1]\n",
        "            best_key = key\n",
        "    best_results[technique] = results[best_key]\n",
        "\n",
        "for i, (name, data) in enumerate(best_results.items(), 1):\n",
        "    plt.subplot(2, 2, i)\n",
        "    plt.plot(data['train_accuracies'], label='Train')\n",
        "    plt.plot(data['test_accuracies'], label='Test')\n",
        "    plt.title(f'{name} - Convergence Graph\\nBest Config: {best_key}')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('convergence_graphs.png')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4mJU8NP3wagK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Creating Summary Tables\n",
        "\n",
        "# Table 1: Best results for each technique\n",
        "best_results = {}\n",
        "for technique in ['No Regularization (GELU)', 'Dropout (GELU)', 'Weight Decay (GELU)', 'Batch Normalization (GELU)']:\n",
        "    best_accuracy = 0\n",
        "    best_key = ''\n",
        "    for key, data in results.items():\n",
        "        if key.startswith(technique) and data['test_accuracies'][-1] > best_accuracy:\n",
        "            best_accuracy = data['test_accuracies'][-1]\n",
        "            best_key = key\n",
        "    best_results[technique] = (best_key, results[best_key])\n",
        "\n",
        "summary_data = {\n",
        "    'Technique': [],\n",
        "    'Best Configuration': [],\n",
        "    'Train Accuracy': [],\n",
        "    'Test Accuracy': []\n",
        "}\n",
        "\n",
        "for technique, (key, data) in best_results.items():\n",
        "    summary_data['Technique'].append(technique)\n",
        "    summary_data['Best Configuration'].append(key)\n",
        "    summary_data['Train Accuracy'].append(data['train_accuracies'][-1])\n",
        "    summary_data['Test Accuracy'].append(data['test_accuracies'][-1])\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "print(\"Best Results for Each Technique:\")\n",
        "print(summary_df.to_string(index=False))\n",
        "summary_df.to_csv('best_accuracy_summary.csv', index=False)\n",
        "\n",
        "# Table 2: All results (for ablation study)\n",
        "all_results_data = {\n",
        "    'Configuration': [],\n",
        "    'Train Accuracy': [],\n",
        "    'Test Accuracy': []\n",
        "}\n",
        "\n",
        "for key, data in results.items():\n",
        "    all_results_data['Configuration'].append(key)\n",
        "    all_results_data['Train Accuracy'].append(data['train_accuracies'][-1])\n",
        "    all_results_data['Test Accuracy'].append(data['test_accuracies'][-1])\n",
        "\n",
        "all_results_df = pd.DataFrame(all_results_data)\n",
        "all_results_df = all_results_df.sort_values('Test Accuracy', ascending=False)\n",
        "print(\"\\nAll Results (sorted by Test Accuracy):\")\n",
        "print(all_results_df.to_string(index=False))\n",
        "all_results_df.to_csv('all_results_summary.csv', index=False)"
      ],
      "metadata": {
        "id": "vkCSh72nwb79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Ablation Study Analysis:\")\n",
        "\n",
        "# Effect of learning rate\n",
        "print(\"\\n1. Effect of Learning Rate:\")\n",
        "for lr in learning_rates:\n",
        "    lr_results = all_results_df[all_results_df['Configuration'].str.contains(f'lr={lr}')]\n",
        "    avg_test_acc = lr_results['Test Accuracy'].mean()\n",
        "    print(f\"  Learning Rate {lr}: Average Test Accuracy = {avg_test_acc:.4f}\")\n",
        "\n",
        "# Effect of batch size\n",
        "print(\"\\n2. Effect of Batch Size:\")\n",
        "for bs in batch_sizes:\n",
        "    bs_results = all_results_df[all_results_df['Configuration'].str.contains(f'batch_size={bs}')]\n",
        "    avg_test_acc = bs_results['Test Accuracy'].mean()\n",
        "    print(f\"  Batch Size {bs}: Average Test Accuracy = {avg_test_acc:.4f}\")\n",
        "\n",
        "# Effect of dropout rate (if applicable)\n",
        "if 'dropout' in all_results_df['Configuration'].iloc[0]:\n",
        "    print(\"\\n3. Effect of Dropout Rate:\")\n",
        "    for dr in dropout_rates:\n",
        "        dr_results = all_results_df[all_results_df['Configuration'].str.contains(f'dropout={dr}')]\n",
        "        avg_test_acc = dr_results['Test Accuracy'].mean()\n",
        "        print(f\"  Dropout Rate {dr}: Average Test Accuracy = {avg_test_acc:.4f}\")\n",
        "\n",
        "# Effect of weight decay (if applicable)\n",
        "if 'weight_decay' in all_results_df['Configuration'].iloc[0]:\n",
        "    print(\"\\n4. Effect of Weight Decay:\")\n",
        "    for wd in weight_decay_values:\n",
        "        wd_results = all_results_df[all_results_df['Configuration'].str.contains(f'weight_decay={wd}')]\n",
        "        avg_test_acc = wd_results['Test Accuracy'].mean()\n",
        "        print(f\"  Weight Decay {wd}: Average Test Accuracy = {avg_test_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "8-AXiaqoaESe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading PTH files for analysis"
      ],
      "metadata": {
        "id": "mT1spCZR_MKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def load_and_evaluate_models(directory):\n",
        "    results = {}\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith('.pth'):\n",
        "            model_name = filename[:-4]  # Remove .pth extension\n",
        "            model = LeNet5GELU()  # Create a new model instance\n",
        "            model.load_state_dict(torch.load(os.path.join(directory, filename)))\n",
        "            model.to(device)\n",
        "            test_accuracy = evaluate_model(model, test_loader)\n",
        "            results[model_name] = test_accuracy\n",
        "    return results\n",
        "\n",
        "# Evaluate all saved models\n",
        "model_directory = '/content/drive/MyDrive/cs5787'\n",
        "evaluation_results = load_and_evaluate_models(model_directory)\n",
        "\n",
        "# Print results\n",
        "for model_name, accuracy in evaluation_results.items():\n",
        "    print(f\"{model_name}: Test Accuracy = {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDFmaqOg_KSq",
        "outputId": "81267be6-02be-47cc-875d-02c5a61ff8ef"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-552b8b117d4f>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(os.path.join(directory, filename)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No Regularization (GELU) (lr=0.01, batch_size=32)_weights: Test Accuracy = 0.7715\n",
            "No Regularization (GELU) (lr=0.01, batch_size=64)_weights: Test Accuracy = 0.8828\n",
            "No Regularization (GELU) (lr=0.01, batch_size=128)_weights: Test Accuracy = 0.8851\n",
            "No Regularization (GELU) (lr=0.001, batch_size=32)_weights: Test Accuracy = 0.9023\n",
            "No Regularization (GELU) (lr=0.001, batch_size=64)_weights: Test Accuracy = 0.9031\n",
            "No Regularization (GELU) (lr=0.001, batch_size=128)_weights: Test Accuracy = 0.8973\n",
            "No Regularization (GELU) (lr=0.0001, batch_size=32)_weights: Test Accuracy = 0.8865\n",
            "No Regularization (GELU) (lr=0.0001, batch_size=64)_weights: Test Accuracy = 0.8830\n",
            "No Regularization (GELU) (lr=0.0001, batch_size=128)_weights: Test Accuracy = 0.8756\n",
            "Dropout (GELU) (lr=0.01, batch_size=32, dropout=0.3)_weights: Test Accuracy = 0.1000\n",
            "Dropout (GELU) (lr=0.01, batch_size=32, dropout=0.5)_weights: Test Accuracy = 0.1000\n",
            "Dropout (GELU) (lr=0.01, batch_size=32, dropout=0.7)_weights: Test Accuracy = 0.1000\n",
            "Dropout (GELU) (lr=0.01, batch_size=64, dropout=0.3)_weights: Test Accuracy = 0.8678\n",
            "Dropout (GELU) (lr=0.01, batch_size=64, dropout=0.5)_weights: Test Accuracy = 0.8222\n",
            "Dropout (GELU) (lr=0.01, batch_size=64, dropout=0.7)_weights: Test Accuracy = 0.1000\n",
            "Dropout (GELU) (lr=0.01, batch_size=128, dropout=0.3)_weights: Test Accuracy = 0.8767\n",
            "Dropout (GELU) (lr=0.01, batch_size=128, dropout=0.5)_weights: Test Accuracy = 0.8615\n",
            "Dropout (GELU) (lr=0.01, batch_size=128, dropout=0.7)_weights: Test Accuracy = 0.7986\n",
            "Dropout (GELU) (lr=0.001, batch_size=32, dropout=0.3)_weights: Test Accuracy = 0.9059\n",
            "Dropout (GELU) (lr=0.001, batch_size=32, dropout=0.5)_weights: Test Accuracy = 0.9055\n",
            "Dropout (GELU) (lr=0.001, batch_size=32, dropout=0.7)_weights: Test Accuracy = 0.8992\n",
            "Dropout (GELU) (lr=0.001, batch_size=64, dropout=0.3)_weights: Test Accuracy = 0.9077\n",
            "Dropout (GELU) (lr=0.001, batch_size=64, dropout=0.5)_weights: Test Accuracy = 0.9118\n",
            "Weight Decay (GELU) (lr=0.01, batch_size=32, weight_decay=0.001)_weights: Test Accuracy = 0.8634\n",
            "Weight Decay (GELU) (lr=0.01, batch_size=32, weight_decay=0.0001)_weights: Test Accuracy = 0.8683\n",
            "Weight Decay (GELU) (lr=0.01, batch_size=32, weight_decay=1e-05)_weights: Test Accuracy = 0.8727\n",
            "Weight Decay (GELU) (lr=0.01, batch_size=64, weight_decay=0.001)_weights: Test Accuracy = 0.8664\n",
            "Weight Decay (GELU) (lr=0.01, batch_size=64, weight_decay=0.0001)_weights: Test Accuracy = 0.8762\n",
            "Weight Decay (GELU) (lr=0.01, batch_size=64, weight_decay=1e-05)_weights: Test Accuracy = 0.8838\n",
            "Weight Decay (GELU) (lr=0.01, batch_size=128, weight_decay=0.001)_weights: Test Accuracy = 0.8820\n",
            "Weight Decay (GELU) (lr=0.01, batch_size=128, weight_decay=0.0001)_weights: Test Accuracy = 0.8938\n",
            "Weight Decay (GELU) (lr=0.01, batch_size=128, weight_decay=1e-05)_weights: Test Accuracy = 0.8954\n",
            "Weight Decay (GELU) (lr=0.001, batch_size=32, weight_decay=0.001)_weights: Test Accuracy = 0.8992\n",
            "Weight Decay (GELU) (lr=0.001, batch_size=32, weight_decay=0.0001)_weights: Test Accuracy = 0.8990\n",
            "Weight Decay (GELU) (lr=0.001, batch_size=32, weight_decay=1e-05)_weights: Test Accuracy = 0.8957\n",
            "Weight Decay (GELU) (lr=0.001, batch_size=64, weight_decay=0.001)_weights: Test Accuracy = 0.8918\n",
            "Weight Decay (GELU) (lr=0.001, batch_size=64, weight_decay=0.0001)_weights: Test Accuracy = 0.9023\n",
            "Weight Decay (GELU) (lr=0.001, batch_size=64, weight_decay=1e-05)_weights: Test Accuracy = 0.8974\n",
            "Weight Decay (GELU) (lr=0.001, batch_size=128, weight_decay=0.001)_weights: Test Accuracy = 0.9029\n",
            "Weight Decay (GELU) (lr=0.001, batch_size=128, weight_decay=0.0001)_weights: Test Accuracy = 0.9026\n",
            "Weight Decay (GELU) (lr=0.001, batch_size=128, weight_decay=1e-05)_weights: Test Accuracy = 0.8971\n",
            "Weight Decay (GELU) (lr=0.0001, batch_size=32, weight_decay=0.001)_weights: Test Accuracy = 0.8856\n",
            "Weight Decay (GELU) (lr=0.0001, batch_size=32, weight_decay=0.0001)_weights: Test Accuracy = 0.9053\n",
            "Weight Decay (GELU) (lr=0.0001, batch_size=32, weight_decay=1e-05)_weights: Test Accuracy = 0.9097\n",
            "Weight Decay (GELU) (lr=0.0001, batch_size=64, weight_decay=0.001)_weights: Test Accuracy = 0.8801\n",
            "Weight Decay (GELU) (lr=0.0001, batch_size=64, weight_decay=0.0001)_weights: Test Accuracy = 0.8939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ygWDA1TBY7o",
        "outputId": "6461b5bc-38fc-4f2f-80c8-2625d3cffb46"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'No Regularization (GELU) (lr=0.01, batch_size=32)_weights': 0.7715,\n",
              " 'No Regularization (GELU) (lr=0.01, batch_size=64)_weights': 0.8828,\n",
              " 'No Regularization (GELU) (lr=0.01, batch_size=128)_weights': 0.8851,\n",
              " 'No Regularization (GELU) (lr=0.001, batch_size=32)_weights': 0.9023,\n",
              " 'No Regularization (GELU) (lr=0.001, batch_size=64)_weights': 0.9031,\n",
              " 'No Regularization (GELU) (lr=0.001, batch_size=128)_weights': 0.8973,\n",
              " 'No Regularization (GELU) (lr=0.0001, batch_size=32)_weights': 0.8865,\n",
              " 'No Regularization (GELU) (lr=0.0001, batch_size=64)_weights': 0.883,\n",
              " 'No Regularization (GELU) (lr=0.0001, batch_size=128)_weights': 0.8756,\n",
              " 'Dropout (GELU) (lr=0.01, batch_size=32, dropout=0.3)_weights': 0.1,\n",
              " 'Dropout (GELU) (lr=0.01, batch_size=32, dropout=0.5)_weights': 0.1,\n",
              " 'Dropout (GELU) (lr=0.01, batch_size=32, dropout=0.7)_weights': 0.1,\n",
              " 'Dropout (GELU) (lr=0.01, batch_size=64, dropout=0.3)_weights': 0.8678,\n",
              " 'Dropout (GELU) (lr=0.01, batch_size=64, dropout=0.5)_weights': 0.8222,\n",
              " 'Dropout (GELU) (lr=0.01, batch_size=64, dropout=0.7)_weights': 0.1,\n",
              " 'Dropout (GELU) (lr=0.01, batch_size=128, dropout=0.3)_weights': 0.8767,\n",
              " 'Dropout (GELU) (lr=0.01, batch_size=128, dropout=0.5)_weights': 0.8615,\n",
              " 'Dropout (GELU) (lr=0.01, batch_size=128, dropout=0.7)_weights': 0.7986,\n",
              " 'Dropout (GELU) (lr=0.001, batch_size=32, dropout=0.3)_weights': 0.9059,\n",
              " 'Dropout (GELU) (lr=0.001, batch_size=32, dropout=0.5)_weights': 0.9055,\n",
              " 'Dropout (GELU) (lr=0.001, batch_size=32, dropout=0.7)_weights': 0.8992,\n",
              " 'Dropout (GELU) (lr=0.001, batch_size=64, dropout=0.3)_weights': 0.9077,\n",
              " 'Dropout (GELU) (lr=0.001, batch_size=64, dropout=0.5)_weights': 0.9118,\n",
              " 'Weight Decay (GELU) (lr=0.01, batch_size=32, weight_decay=0.001)_weights': 0.8634,\n",
              " 'Weight Decay (GELU) (lr=0.01, batch_size=32, weight_decay=0.0001)_weights': 0.8683,\n",
              " 'Weight Decay (GELU) (lr=0.01, batch_size=32, weight_decay=1e-05)_weights': 0.8727,\n",
              " 'Weight Decay (GELU) (lr=0.01, batch_size=64, weight_decay=0.001)_weights': 0.8664,\n",
              " 'Weight Decay (GELU) (lr=0.01, batch_size=64, weight_decay=0.0001)_weights': 0.8762,\n",
              " 'Weight Decay (GELU) (lr=0.01, batch_size=64, weight_decay=1e-05)_weights': 0.8838,\n",
              " 'Weight Decay (GELU) (lr=0.01, batch_size=128, weight_decay=0.001)_weights': 0.882,\n",
              " 'Weight Decay (GELU) (lr=0.01, batch_size=128, weight_decay=0.0001)_weights': 0.8938,\n",
              " 'Weight Decay (GELU) (lr=0.01, batch_size=128, weight_decay=1e-05)_weights': 0.8954,\n",
              " 'Weight Decay (GELU) (lr=0.001, batch_size=32, weight_decay=0.001)_weights': 0.8992,\n",
              " 'Weight Decay (GELU) (lr=0.001, batch_size=32, weight_decay=0.0001)_weights': 0.899,\n",
              " 'Weight Decay (GELU) (lr=0.001, batch_size=32, weight_decay=1e-05)_weights': 0.8957,\n",
              " 'Weight Decay (GELU) (lr=0.001, batch_size=64, weight_decay=0.001)_weights': 0.8918,\n",
              " 'Weight Decay (GELU) (lr=0.001, batch_size=64, weight_decay=0.0001)_weights': 0.9023,\n",
              " 'Weight Decay (GELU) (lr=0.001, batch_size=64, weight_decay=1e-05)_weights': 0.8974,\n",
              " 'Weight Decay (GELU) (lr=0.001, batch_size=128, weight_decay=0.001)_weights': 0.9029,\n",
              " 'Weight Decay (GELU) (lr=0.001, batch_size=128, weight_decay=0.0001)_weights': 0.9026,\n",
              " 'Weight Decay (GELU) (lr=0.001, batch_size=128, weight_decay=1e-05)_weights': 0.8971,\n",
              " 'Weight Decay (GELU) (lr=0.0001, batch_size=32, weight_decay=0.001)_weights': 0.8856,\n",
              " 'Weight Decay (GELU) (lr=0.0001, batch_size=32, weight_decay=0.0001)_weights': 0.9053,\n",
              " 'Weight Decay (GELU) (lr=0.0001, batch_size=32, weight_decay=1e-05)_weights': 0.9097,\n",
              " 'Weight Decay (GELU) (lr=0.0001, batch_size=64, weight_decay=0.001)_weights': 0.8801,\n",
              " 'Weight Decay (GELU) (lr=0.0001, batch_size=64, weight_decay=0.0001)_weights': 0.8939}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}